# **CartPole DQN AI Agent** ğŸš€  

A **Deep Q-Learning AI Agent** for **CartPole-v1** using **TensorFlow & OpenAI Gym**.  
The agent learns to balance a pole through **reinforcement learning**, using **experience replay** and **target networks**.  

---

## ğŸ“Œ **Overview**  
This project demonstrates how to train an **AI agent** using **Deep Q-Learning (DQN)** to play **CartPole-v1**, a classic reinforcement learning environment.  
The agent learns **optimal actions** over time by interacting with the environment, storing experiences, and improving its decision-making process through deep learning.  

---

## **ğŸš€ Features**  
âœ” **Deep Q-Network (DQN) implementation** using TensorFlow  
âœ” **Experience Replay** to improve learning stability  
âœ” **Target Q-Network** for better convergence  
âœ” **Epsilon-Greedy Exploration** to balance exploration & exploitation  
âœ” **Trained model saving & evaluation**  
âœ” **Runs on CPU, GPU, and Apple M1/M2 (TensorFlow-Metal)**  

---

## ğŸ›  **Installation & Setup**  

### **1ï¸âƒ£ Clone the Repository**  
```sh
git clone https://github.com/your-username/cartpole-dqn-ai-agent.git
cd cartpole-dqn-ai-agent
```

### **2ï¸âƒ£ Install Dependencies**  
To install the required dependencies, run:  
```sh
pip install -r requirements.txt
<br>
If you are using Apple M1/M2, install TensorFlow with GPU support:

```sh
pip install tensorflow-macos tensorflow-metal

### **3ï¸âƒ£ Run Training**  
To train the agent, run:  
```sh
python main.py
---

### ğŸ“ˆ **Training Results**
Below is the training progress:
```sh
Episode 100 | Avg Reward (last 100 eps): 17.76 | Epsilon: 0.606
Episode 200 | Avg Reward (last 100 eps): 43.13 | Epsilon: 0.367
Episode 300 | Avg Reward (last 100 eps): 110.69 | Epsilon: 0.222
Episode 354 | Avg Reward (last 100 eps): 201.86 | Epsilon: 0.170 âœ…
Environment solved in 354 episodes!

Total Training Time: 599.87 s (10.00 min)

